# Simplex Method

Our first goal is to find a general method for solving linear programs.
However, instead of solving linear programs in their full generality, we'll construct an algorithm for solving standard linear programs.
We will see later that every linear program can be *standardized* and hence it suffices to construct an algorithm for solving standard linear programs.

## Standard Linear Programs


::: {.definition}

A **standard linear program** is an optimization problem of the following form:

\begin{equation}
  \begin{array}{lrrrrrrrrr}
    \mbox{maximize: } & c_0 & + & c_1 x_1 & + & \dots & + & c_n x_n & \\
    \mbox{subject to: } 
      & & & a_{11} x_1 & + & \dots & + & a_{1n} x_n & \leq & b_1 \\
      & & & a_{21} x_1 & + & \dots & + & a_{2n} x_n & \leq & b_2 \\
      & & & & & \vdots &  \\
      & & & a_{m1} x_1 & + & \dots & + & a_{mn} x_n & \leq & b_m \\
      & & & x_1, & x_2, & \dots &, & x_n & \geq & 0
  \end{array} 
  (\#eq:standard-lp)
\end{equation}
where $c_i$, $a_{ij}$, and $b_j$ are real constants. The variables $x_1, \dots, x_n$ are called **decision variables**. A tuple $(x_1, \dots, x_n)$ that satisfy *all* the constraints is called a **feasible solution** and the set of all feasible solutions is called the **feasible region**. 

:::

::: {.example}

Equation \@ref(eq:bond-portfolio-lp) is an example of a standard linear program with 2 decision variables, 3 constraints, and the feasible region being a quadrilateral. 

:::

::: {.definition}

For each constraint, we introduce a **slack variable** by subtracting the LHS from the RHS as follows.

\begin{equation}
  \begin{array}{lrrrrrrrrr}
      w_1 & = & b_1 & - & a_{11} x_1 & - & \dots & - & a_{1n} x_n \\
      w_2 & = & b_2 & - & a_{21} x_1 & - & \dots & - & a_{2n} x_n \\
      & & & & & \vdots &  \\
      w_m & = & b_m & - & a_{m1} x_1 & - & \dots & - & a_{mn} x_n 
  \end{array} 
  (\#eq:slack-variables-def)
\end{equation}

:::

We can think of the slack variable $w_i$ as measuring the *slackness* in the $i^{th}$ constraint. The $i^{th}$ constraint is strictly met exactly when $w_i$ is zero. Using the slack variables, the linear program \@ref(eq:standard-lp) can be succinctly rewritten as:

\begin{equation}
  w_1, \dots, w_m, x_1, \dots, x_n \geq 0.
\end{equation}

::: {.example}

The slack variables for the linear program \@ref(eq:bond-portfolio-lp) are as follows:

\begin{equation}
  \begin{array}{rlllllll}
  w_1 & = & 3.6 & - & 3x & - & 6y \\
  w_2 & = & 1.5 & - & 2x & - & y \\
  w_3 & = & 1 & - & x & - & y.
  \end{array}
\end{equation}

In terms of these slack variables, the constraints can be rewritten as $x, y, w_1, w_2, w_3 \ge 0$ and the boundaries of the feasible region are given by $x = 0, y = 0, w_1 = 0, w_2 = 0, w_3 = 0$.


```{r, fig-bond-portfolio-slack}

source("graphs/bond-portfolio-slack.R", local = knitr::knit_global())

```

:::

To construct the simplex method, we need a few facts about the geometry of the feasible region.

::: {.definition}
A **basic feasible solution** of the standard linear program \@ref(eq:standard-lp) is defined as a feasible solution at which at least $n$ basic or decision variables equal 0. A BFS where exactly $n$ basic or decision variables are 0 is called **non-degenerate**. A BFS where more than $n$ basic or decision variables are 0 is called **degenerate**. At a non-degenerate BFS, the $n$ variables that equal 0 are called **non-basic** and the remaining $m$ variables are called **basic**.
At a degenerate BFS, we choose some $n$ vanishing variables to be non-basic and call the rest of the variables basic. 
:::


::: {.example}

The feasible region for the linear program \@ref(eq:bond-portfolio-lp) has four non-degenerate basic feasible solutions: $(0,0)$, $(0.75, 0)$, $(0, 0.6)$, and $(0.6, 0.3)$ and the optimal solution is attained at the BFS $(0.6, 0.3)$. At the origin, the non-basic variables are $x, y$ and the basic variables are $w_1, w_2, w_3$. At the optimal solution, the non-basic variables are $w_1, w_2$ and the basic variables are $x, y, w_3$.

:::

We will assume the following theorem without proof.

::: {.theorem}

If a standard linear program has an optimal solution, then there is a basic feasible solution which is optimal. 

:::

Note that the above theorem claims neither the existence nor the uniqueness of an optimal solution. It is possible that no optimal solution exists or that the optimal value is attained more than one points, possible at a non-BFS. 

## The Idea

The simplex method is an iterative process for finding the optimal solution of a standard linear program. It starts at some vertex of the feasible region and in each step moves to an adjacent vertex with a higher objective value. The following picture shows one possible run of the simplex method for solving the linear program \@ref(eq:bond-portfolio-lp).

```{r, sample-run, fig.cap="A possible run of the simplex algorithm."}

source("graphs/bond-portfolio-simplex.R", local = knitr::knit_global())

```

In each step, one non-basic variable **enters** the set of basic variables and one basic variable **leaves** the set of basic variables. The table below explains how these sets are getting updated in the sample simplex algorithm run in Figure \@ref(fig:sample-run).

|  | Leaving variable | Entering variable | Basic variables | Non-basic variables |
| - | - | - | - | - |
| Start |  |  | $\{w_1, w_2, w_3\}$ | $\{x, y\}$ |
| Step 1 | $w_2$ | $x$ | $\{w_1, x, w_3\}$ |$\{w_2, y\}$ | 
| Step 2 | $w_1$ | $y$ | $\{y, x, w_3\}$ |$\{w_2, w_1\}$ | 

```{r, fig-bond-portfolio-entering}

source("graphs/bond-portfolio-entering.R", local = knitr::knit_global())

```

Using this terminology, our goal at each step is reduced to finding the entering and leaving variables. 
To do this algebraically, we'll introduce the notion of dictionaries. 

::: {.definition}

The **dictionary** at a basic feasible solution is a set of equations describing the objective function and the constraints in terms of the non-basic variables. 

:::

::: {.example #dictionaries}

Consider \@ref(eq:bond-portfolio-lp) again. At the origin, the non-basic variables are $x, y$ and hence the initial dictionary is:
\begin{equation}
  \begin{array}{rlrrrrr}
  \mbox{objective} & = & 0 & + & 4x & + & 3y \\
  w_1 & = & 3.6 & - & 3x & - & 6y \\
  w_2 & = & 1.5 & - & 2x & - & y \\
  w_3 & = & 1 & - & x & - & y.
  \end{array}
  (\#eq:example-dictionary-1)
\end{equation}

After the first step of the simplex algorithm, the non-basic variables are $w_2, y$. We can write $x$ in terms of $w_2$ to get 

\begin{equation}
  x = 0.75 - 0.5 w_2 - 0.5 y
\end{equation}

We can substitute this into the initial dictionary to get the dictionary after the first step: 

\begin{equation}
  \begin{array}{rlrrrrr}
  \mbox{objective} & = & 3 & + & (-2)w_2 & + & y \\
  w_1 & = & 1.35 & - & (-1.5) w_2 & - & 4.5y \\
  x & = & 0.75 & - & 0.5 w_2 & - & 0.5y \\
  w_3 & = & 0.25 & - & (-0.5) w_2 & - & 0.5y.
  \end{array}
  (\#eq:example-dictionary-2)
\end{equation}

Finally, the non-basic variables at the optimal solution are $w_1, w_2$. 
We can repeat the above process and get the dictionary for the optimal solution:

\begin{equation}
  \begin{array}{rlrrrrr}
  \mbox{objective} & = & 3.3 & + & (-5/3)w_2 & + & (-2/9)w_1 \\
  y & = & 0.3 & - & (-1/3) w_2 & - & 2/9 w_1 \\
  x & = & 0.6 & - & 2/3 w_2 & - & (-1/9) w_1 \\
  w_3 & = & 0.1 & - & (-1/3) w_2 & - & (-1/9) w_1.
  \end{array}
  (\#eq:example-dictionary-3)
\end{equation}

:::


::: {.remark} 

From the dictionary, one can extract the set of basic variables and the set of non-basic variables by looking at the variables appearing on the LHS and RHS, respectively. Furthermore, by setting the non-basic variables to 0, we obtain the very useful fact that 

- the values of the basic variables are simply the constants "$b_i$", and 
- the value of the objective function is the constant "$c_0$".

For example, from the final dictionary above, we can immediately see that $x = 0.6$, $y = 0.3$, $w_3 = 0.9$, and the objective value is $3.3%$ (and $w_1 = 0$ and $w_2 = 0.3$) at the optimal solution.

:::

## Algorithm

To describe the simplex method, we'll assume for now that all the basic feasible solutions are non-degenerate. 
At each BFS we will let $\{\bar{w}_1, \dots, \bar{w}_m\}$ denote the set of basic variables, $\{\bar{x}_1, \dots, \bar{x}_n\}$ denote the set of non-basic variables. We'll let $\bar{c}_j$, $\bar{b}_i$, and $\bar{a}_{ij}$ be the constants appearing in the dictionary at the BFS so that at the start of each step the dictionary is as follows:

\begin{equation}
  \begin{array}{rrrrrrrrrr}
  \mbox{objective} & = & \bar{c}_0 & + & \bar{c}_1\bar{x}_1 & + & \dots & + & \bar{c}_n\bar{x}_n \\
      \bar{w}_1 & = & \bar{b}_1 & - & \bar{a}_{11} \bar{x}_1 & - & \dots & - & \bar{a}_{1n} \bar{x}_n \\
      \bar{w}_2 & = & \bar{b}_2 & - & \bar{a}_{21} \bar{x}_1 & - & \dots & - & \bar{a}_{2n} \bar{x}_n \\
      & & & & & \vdots &  \\
      \bar{w}_m & = & \bar{b}_m & - & \bar{a}_{m1} \bar{x}_1 & - & \dots & - & \bar{a}_{mn} \bar{x}_n 
  \end{array} 
  (\#eq:standard-dictionary)
\end{equation}
