<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Separation Theorems | Introduction to Optimization</title>
  <meta name="description" content="Chapter 11 Separation Theorems | Introduction to Optimization." />
  <meta name="generator" content="bookdown 0.26 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Separation Theorems | Introduction to Optimization" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Chapter 11 Separation Theorems | Introduction to Optimization." />
  <meta name="github-repo" content="apurvanakade/Introduction-to-Optimization" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Separation Theorems | Introduction to Optimization" />
  
  <meta name="twitter:description" content="Chapter 11 Separation Theorems | Introduction to Optimization." />
  

<meta name="author" content="Apurva Nakade" />


<meta name="date" content="2022-06-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="convex-programming.html"/>
<link rel="next" href="interior-point-methods.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="part"><span><b>I Simplex Method</b></span></li>
<li class="chapter" data-level="2" data-path="standard-linear-program.html"><a href="standard-linear-program.html"><i class="fa fa-check"></i><b>2</b> Standard Linear Program</a></li>
<li class="chapter" data-level="3" data-path="the-simplex-method.html"><a href="the-simplex-method.html"><i class="fa fa-check"></i><b>3</b> The Simplex Method</a>
<ul>
<li class="chapter" data-level="3.1" data-path="the-simplex-method.html"><a href="the-simplex-method.html#the-simplex-step"><i class="fa fa-check"></i><b>3.1</b> The Simplex Step</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="the-simplex-method.html"><a href="the-simplex-method.html#entering-variable"><i class="fa fa-check"></i><b>3.1.1</b> Entering variable</a></li>
<li class="chapter" data-level="3.1.2" data-path="the-simplex-method.html"><a href="the-simplex-method.html#leaving-variable"><i class="fa fa-check"></i><b>3.1.2</b> Leaving Variable</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="the-simplex-method.html"><a href="the-simplex-method.html#tableau-notation"><i class="fa fa-check"></i><b>3.2</b> Tableau Notation</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="initialization.html"><a href="initialization.html"><i class="fa fa-check"></i><b>4</b> Initialization</a>
<ul>
<li class="chapter" data-level="4.1" data-path="initialization.html"><a href="initialization.html#auxiliary-linear-program"><i class="fa fa-check"></i><b>4.1</b> Auxiliary Linear Program</a></li>
<li class="chapter" data-level="4.2" data-path="initialization.html"><a href="initialization.html#combined-tableau"><i class="fa fa-check"></i><b>4.2</b> Combined tableau</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="cycling.html"><a href="cycling.html"><i class="fa fa-check"></i><b>5</b> Cycling</a>
<ul>
<li class="chapter" data-level="5.1" data-path="cycling.html"><a href="cycling.html#degeneracy"><i class="fa fa-check"></i><b>5.1</b> Degeneracy</a></li>
<li class="chapter" data-level="5.2" data-path="cycling.html"><a href="cycling.html#blands-rule"><i class="fa fa-check"></i><b>5.2</b> Bland’s Rule</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="standardization.html"><a href="standardization.html"><i class="fa fa-check"></i><b>6</b> Standardization</a>
<ul>
<li class="chapter" data-level="6.1" data-path="standardization.html"><a href="standardization.html#equivalence-of-linear-programs"><i class="fa fa-check"></i><b>6.1</b> Equivalence of Linear Programs</a></li>
</ul></li>
<li class="part"><span><b>II Duality Theory</b></span></li>
<li class="chapter" data-level="7" data-path="dual-linear-program.html"><a href="dual-linear-program.html"><i class="fa fa-check"></i><b>7</b> Dual Linear Program</a>
<ul>
<li class="chapter" data-level="7.1" data-path="dual-linear-program.html"><a href="dual-linear-program.html#general-linear-program"><i class="fa fa-check"></i><b>7.1</b> General Linear Program</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="weak-and-strong-duality.html"><a href="weak-and-strong-duality.html"><i class="fa fa-check"></i><b>8</b> Weak and Strong Duality</a>
<ul>
<li class="chapter" data-level="8.1" data-path="weak-and-strong-duality.html"><a href="weak-and-strong-duality.html#weak-duality"><i class="fa fa-check"></i><b>8.1</b> Weak Duality</a></li>
<li class="chapter" data-level="8.2" data-path="weak-and-strong-duality.html"><a href="weak-and-strong-duality.html#strong-duality"><i class="fa fa-check"></i><b>8.2</b> Strong Duality</a></li>
<li class="chapter" data-level="8.3" data-path="weak-and-strong-duality.html"><a href="weak-and-strong-duality.html#complimentary-slackness"><i class="fa fa-check"></i><b>8.3</b> Complimentary slackness</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html"><i class="fa fa-check"></i><b>9</b> Sensitivity Analysis</a>
<ul>
<li class="chapter" data-level="9.1" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html#dictionaries-revisited"><i class="fa fa-check"></i><b>9.1</b> Dictionaries Revisited</a></li>
<li class="chapter" data-level="9.2" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html#range-of-optimality---constraints"><i class="fa fa-check"></i><b>9.2</b> Range of Optimality - Constraints</a></li>
<li class="chapter" data-level="9.3" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html#shadow-prices"><i class="fa fa-check"></i><b>9.3</b> Shadow Prices</a></li>
<li class="chapter" data-level="9.4" data-path="sensitivity-analysis.html"><a href="sensitivity-analysis.html#sensitivity-analysis---objective"><i class="fa fa-check"></i><b>9.4</b> Sensitivity analysis - Objective</a></li>
</ul></li>
<li class="part"><span><b>III Non-Linear Programming</b></span></li>
<li class="chapter" data-level="10" data-path="convex-programming.html"><a href="convex-programming.html"><i class="fa fa-check"></i><b>10</b> Convex Programming</a></li>
<li class="chapter" data-level="11" data-path="separation-theorems.html"><a href="separation-theorems.html"><i class="fa fa-check"></i><b>11</b> Separation Theorems</a>
<ul>
<li class="chapter" data-level="11.1" data-path="separation-theorems.html"><a href="separation-theorems.html#farkas-lemma"><i class="fa fa-check"></i><b>11.1</b> Farkas’ Lemma</a></li>
<li class="chapter" data-level="11.2" data-path="separation-theorems.html"><a href="separation-theorems.html#separating-hyperplane-theorem"><i class="fa fa-check"></i><b>11.2</b> Separating Hyperplane Theorem</a></li>
<li class="chapter" data-level="11.3" data-path="separation-theorems.html"><a href="separation-theorems.html#equivalence-with-strong-duality"><i class="fa fa-check"></i><b>11.3</b> Equivalence with Strong Duality</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="interior-point-methods.html"><a href="interior-point-methods.html"><i class="fa fa-check"></i><b>12</b> Interior Point Methods</a>
<ul>
<li class="chapter" data-level="12.1" data-path="interior-point-methods.html"><a href="interior-point-methods.html#gradient-descent"><i class="fa fa-check"></i><b>12.1</b> Gradient Descent</a></li>
<li class="chapter" data-level="12.2" data-path="interior-point-methods.html"><a href="interior-point-methods.html#interior-point-method"><i class="fa fa-check"></i><b>12.2</b> Interior Point Method</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="kkt-conditions.html"><a href="kkt-conditions.html"><i class="fa fa-check"></i><b>13</b> KKT conditions</a></li>
<li class="part"><span><b>IV Applications</b></span></li>
<li class="chapter" data-level="14" data-path="l1-regression.html"><a href="l1-regression.html"><i class="fa fa-check"></i><b>14</b> L1-Regression</a></li>
<li class="chapter" data-level="15" data-path="network-flow.html"><a href="network-flow.html"><i class="fa fa-check"></i><b>15</b> Network Flow</a>
<ul>
<li class="chapter" data-level="15.1" data-path="network-flow.html"><a href="network-flow.html#min-cut"><i class="fa fa-check"></i><b>15.1</b> Min-cut</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="integer-programming.html"><a href="integer-programming.html"><i class="fa fa-check"></i><b>16</b> Integer Programming</a>
<ul>
<li class="chapter" data-level="16.1" data-path="integer-programming.html"><a href="integer-programming.html#branch-and-bound"><i class="fa fa-check"></i><b>16.1</b> Branch and Bound</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Optimization</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="separation-theorems" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number">Chapter 11</span> Separation Theorems<a href="separation-theorems.html#separation-theorems" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>We’ll next prove a couple of <em>geometric</em> results that are equivalent to strong duality theorem (Theorem <a href="weak-and-strong-duality.html#thm:strong-duality">8.2</a>).</p>
<div id="farkas-lemma" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> Farkas’ Lemma<a href="separation-theorems.html#farkas-lemma" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="theorem">
<p><span id="thm:farkas-lemma" class="theorem"><strong>Theorem 11.1  (Farkas' lemma) </strong></span>Let <span class="math inline">\(A\)</span> be an <span class="math inline">\(m \times n\)</span> matrix and <span class="math inline">\(b\)</span> be a vector in <span class="math inline">\(\mathbb{R}^m\)</span>.
Exactly one of the following systems has a solution:
<span class="math display" id="eq:farkas-eq1">\[\begin{align}
  A x &amp; = b \\
  x &amp; \ge 0.
\tag{11.1}
\end{align}\]</span>
<span class="math display" id="eq:farkas-eq2">\[\begin{align}
  y^T A &amp; \ge 0 \\
  y^T b &amp; &lt; 0.
\tag{11.2}
\end{align}\]</span>
<!-- 
1. $A x = b$, $x \ge 0.$
2. $y^T A \ge 0$, $y^T b < 0.$ --></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-63" class="proof"><em>Proof</em>. </span>We’ll prove Farkas’ lemma using strong duality. Consider the following linear program:
<span class="math display" id="eq:farkas-primal">\[\begin{equation}
  \begin{array}{llll}
    \mbox{maximize: } &amp; 0 \\
    \mbox{subject to: }
      &amp; A x &amp; = &amp; b \\
      &amp; x &amp; \ge &amp; 0.
  \end{array}
\tag{11.3}
\end{equation}\]</span>
The optimal solution to the linear program <a href="separation-theorems.html#eq:farkas-primal">(11.3)</a> is a feasible solution to <a href="separation-theorems.html#eq:farkas-eq1">(11.1)</a>. The dual to this linear program is
<span class="math display" id="eq:farkas-dual">\[\begin{equation}
  \begin{array}{llll}
    \mbox{minimize: } &amp; y^T b \\
    \mbox{subject to: }
      &amp; y^T A &amp; \ge &amp; 0.
  \end{array}
\tag{11.4}
\end{equation}\]</span></p>
<p><strong>Case 1:</strong> Suppose <a href="separation-theorems.html#eq:farkas-eq1">(11.1)</a> has a solution.</p>
<p>In this case, <a href="separation-theorems.html#eq:farkas-primal">(11.3)</a> has an optimal solution. By strong duality, <a href="separation-theorems.html#eq:farkas-dual">(11.4)</a> also has an optimal solution with optimal objective <span class="math inline">\(0\)</span>. So, the minimum value of <span class="math inline">\(y^T b\)</span> is <span class="math inline">\(0\)</span> and hence the system <a href="separation-theorems.html#eq:farkas-eq2">(11.2)</a> does not have a solution.</p>
<p><strong>Case 2:</strong> Suppose <a href="separation-theorems.html#eq:farkas-eq1">(11.1)</a> does not have a solution.</p>
<p>In this case, <a href="separation-theorems.html#eq:farkas-primal">(11.3)</a> has no optimal solution. By strong duality, neither does <a href="separation-theorems.html#eq:farkas-dual">(11.4)</a>. So, <a href="separation-theorems.html#eq:farkas-dual">(11.4)</a> is either infeasible or unbounded. As <span class="math inline">\(y = 0\)</span> is a feasible solution to <a href="separation-theorems.html#eq:farkas-dual">(11.4)</a> it cannot be infeasible, and hence it must be unbounded. But this means that the value of <span class="math inline">\(y^T b\)</span> can be made arbitrarily small, and in particular, can be made negative. Hence, the system <a href="separation-theorems.html#eq:farkas-eq2">(11.2)</a> has a solution.</p>
</div>
<p>We can interpret Farkas’ lemma geometrically using convex cones and separating hyperplanes.</p>
</div>
<div id="separating-hyperplane-theorem" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> Separating Hyperplane Theorem<a href="separation-theorems.html#separating-hyperplane-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- Let $\{v_1, \dots, v_n\}$ be a set of vectors in $\mathbb{R}^m$.  -->
<div class="definition">
<p><span id="def:unlabeled-div-64" class="definition"><strong>Definition 11.1  </strong></span>The <strong>convex cone</strong> of a finite set of vectors in <span class="math inline">\(\mathbb{R}^m\)</span> is the set of positive linear combinations of vectors in the set.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>
<span class="math display">\[\begin{align*}
  C_+(v_1, \dots, v_n) &amp; := \{c_1 v_1 + \dots + c_n v_n \mid c_i \ge 0 \}.
\end{align*}\]</span></p>
</div>
<div class="definition">
<p><span id="def:unlabeled-div-65" class="definition"><strong>Definition 11.2  </strong></span>A <strong>hyperplane</strong> in <span class="math inline">\(\mathbb{R}^m\)</span> is the set of solutions to a single linear equation.
The complement of a hyperplane in <span class="math inline">\(\mathbb{R}^n\)</span> consists of two connected components.
The closures of these components are called <strong>half-spaces</strong>.</p>
</div>
<p>If the equation of the hyperplane is given by <span class="math inline">\(b^T y = b_0\)</span>, where <span class="math inline">\(b\)</span> is a vector in <span class="math inline">\(\mathbb{R}^m\)</span> and <span class="math inline">\(b_0 \in \mathbb{R}\)</span>, then the corresponding two half-spaces are described by <span class="math inline">\(b^T y \le b_0\)</span> and <span class="math inline">\(b^T y \ge b_0\)</span>.</p>
<div class="definition">
<p><span id="def:unlabeled-div-66" class="definition"><strong>Definition 11.3  </strong></span>We say that a hyperplane <span class="math inline">\(H\)</span> <strong>separates</strong> two subsets <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> of <span class="math inline">\(\mathbb{R}^m\)</span> if <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_2\)</span> do not intersect <span class="math inline">\(H\)</span> and belong to the two different half-spaces of <span class="math inline">\(H\)</span>.</p>
</div>
<p>Using convex cones and separating hyperplanes, we can reinterpret <a href="separation-theorems.html#thm:farkas-lemma">11.1</a> as follows.</p>
<div class="theorem">
<p><span id="thm:farkas-geometry" class="theorem"><strong>Theorem 11.2  (Geometric version of Farkas' lemma) </strong></span>Let <span class="math inline">\(v_1, \dots, v_n, b\)</span> be vectors in <span class="math inline">\(\mathbb{R}^m\)</span>. Exactly one of the following statements is true:</p>
<ol style="list-style-type: decimal">
<li>Either <span class="math inline">\(b\)</span> lies inside <span class="math inline">\(C_+(v_1, \dots, v_n)\)</span>, or</li>
<li>There is a hyperplane <span class="math inline">\(H\)</span> that separates <span class="math inline">\(b\)</span> from <span class="math inline">\(C_+(v_1, \dots, v_n)\)</span>.</li>
</ol>
</div>
<p>A point <span class="math inline">\(b\)</span> and a convex cone <span class="math inline">\(C_+(v_1, \dots, v_n)\)</span> are convex subsets of <span class="math inline">\(\mathbb{R}^m\)</span>.
The statement of Farkas’ lemma <a href="separation-theorems.html#thm:farkas-geometry">11.2</a> can be generalized to arbitrary convex sets using metric topology.
For now, we’ll generalize it to convex polyhedra.</p>
<div class="definition">
<p><span id="def:unlabeled-div-67" class="definition"><strong>Definition 11.4  </strong></span>Intersection of finitely many half-spaces is called a <strong>convex polyhedron</strong>.</p>
</div>
<p>So, a convex polyhedron is the set of solutions to a system of linear inequalities <span class="math inline">\(A x \le b\)</span>.
But this set is precisely the feasible region of a linear program!
The class of convex polyhedra is very large and all geometric “linear” convex objects, like points, lines, planes, half-spaces, hyperplanes, convex cones, etc. can be realized as convex polyhedra.</p>
<p>The following is an extension of Farkas’ lemma to convex polyhedra (proof in the exercises below).</p>
<div class="theorem">
<p><span id="thm:separating-hyperplane" class="theorem"><strong>Theorem 11.3  (Separating Hyperplane Theorem) </strong></span>Any two non-empty, disjoint, convex polyhedra in <span class="math inline">\(\mathbb{R}^m\)</span> can be separated by a hyperplane.</p>
</div>
<div class="exercise">
<p><span id="exr:farkas-variant" class="exercise"><strong>Exercise 11.1  </strong></span>Prove the following variant of Farkas’ lemma: Let <span class="math inline">\(A\)</span> be an <span class="math inline">\(m \times n\)</span> matrix and let <span class="math inline">\(b\)</span> be a vector in <span class="math inline">\(\mathbb{R}^m\)</span>.
Exactly one of the following systems has a solution:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(Ax \le b\)</span>,</li>
<li><span class="math inline">\(y^T b &lt; 0\)</span>, <span class="math inline">\(y^T A = 0\)</span>, and <span class="math inline">\(y \ge 0\)</span>.</li>
</ol>
</div>
<div class="exercise">
<p><span id="exr:unlabeled-div-68" class="exercise"><strong>Exercise 11.2  </strong></span>Let <span class="math inline">\(P_1\)</span> be the convex polyhedron defined by <span class="math inline">\(A_1 x \le b_1\)</span> and let <span class="math inline">\(P_2\)</span> be the convex polyhedron defined by <span class="math inline">\(A_2 x \le b_2\)</span> where <span class="math inline">\(A_1\)</span>, <span class="math inline">\(A_2\)</span>, <span class="math inline">\(b_1\)</span>, and <span class="math inline">\(b_2\)</span> have sizes <span class="math inline">\(m_1 \times n\)</span>, <span class="math inline">\(m_2 \times n\)</span>, <span class="math inline">\(m_1\)</span>, and <span class="math inline">\(m_2\)</span>, respectively. Suppose the system
<span class="math display" id="eq:eq1">\[\begin{equation}
  \begin{bmatrix} A_1 \\ A_2 \end{bmatrix}
  x
  \le
  \begin{bmatrix} b_1 \\ b_2 \end{bmatrix}
  \tag{11.5}
\end{equation}\]</span>
does not have a solution.</p>
<ol style="list-style-type: decimal">
<li>Apply the above variant of Farkas’ lemma to <a href="separation-theorems.html#eq:eq1">(11.5)</a> to obtain vectors <span class="math inline">\(y_1\)</span>, <span class="math inline">\(y_2\)</span> of size <span class="math inline">\(m_1\)</span> and <span class="math inline">\(m_2\)</span>, respectively. Define <span class="math inline">\(c^T := y_1^T A_1\)</span>, <span class="math inline">\(d_1 := y_1^T b_1\)</span>, and <span class="math inline">\(d_2 := -y_2^T b_2\)</span>.</li>
<li>Show that <span class="math inline">\(d_1 &lt; d_2\)</span>.</li>
<li>Show that <span class="math inline">\(A_1 x \le b_1\)</span> implies <span class="math inline">\(c^T x \le d_1\)</span>.</li>
<li>Show that <span class="math inline">\(A_2 x \le b_2\)</span> implies <span class="math inline">\(c^T x \ge d_2\)</span>.</li>
<li>Conclude that there exists a hyperplane separating <span class="math inline">\(P_1\)</span> and <span class="math inline">\(P_2\)</span>.</li>
</ol>
</div>
</div>
<div id="equivalence-with-strong-duality" class="section level2 hasAnchor" number="11.3">
<h2><span class="header-section-number">11.3</span> Equivalence with Strong Duality<a href="separation-theorems.html#equivalence-with-strong-duality" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>It is possible to prove Strong Duality using Farkas’ lemma, which itself can be proven using metric topology. So, Strong Duality, Farkas’ lemma, and Separating Hyperplane Theorem should all be thought of as equivalent to each other. We provide below a proof of Strong Duality (Theorem <a href="weak-and-strong-duality.html#thm:strong-duality">8.2</a>) using Farkas’ lemma.</p>
<div class="proof">
<p><span id="unlabeled-div-69" class="proof"><em>Proof</em>. </span>Consider the system of equations</p>
<p><span class="math display" id="eq:strong-using-farkas">\[\begin{equation}
\begin{split}
Ax &amp; \le b \\
-A^T y &amp; \le -c \\
x, y &amp; \ge 0 \\
-c^T x + b^T y &amp; \le 0.
\end{split}
\tag{11.6}
\end{equation}\]</span></p>
<p>Suppose this system has a feasible solution. The first three equations are equivalent to saying that <span class="math inline">\(x\)</span> is primal-feasible and <span class="math inline">\(y\)</span> is dual-feasible. If such a solution exists, by Weak Duality (Theorem <a href="weak-and-strong-duality.html#thm:weak-duality">8.1</a>) we know that <span class="math inline">\(c^T x \le b^T y\)</span>. So, the only way the fourth inequality is satisfied is if <span class="math inline">\(c^T x = b^T y\)</span> i.e. the primal-objective value at <span class="math inline">\(x\)</span> equals the dual-objective value at <span class="math inline">\(y\)</span>. But by Weak Duality, these must then be the optimal solutions thereby proving Strong Duality. So, it suffices to show that <a href="separation-theorems.html#eq:strong-using-farkas">(11.6)</a> has a feasible solution if the primal has an optimal solution.</p>
<p>We prove this by contradiction. Suppose the primal has an optimal solution but <a href="separation-theorems.html#eq:strong-using-farkas">(11.6)</a> does not have a feasible solution. We rewrite the system as
<span class="math display">\[\begin{align*}
    \begin{bmatrix} A &amp; 0 \\ 0 &amp; -A^T \\ -c^T &amp; b^T \end{bmatrix}
    \begin{bmatrix} x \\ y  \end{bmatrix}
      &amp; \le
    \begin{bmatrix} b \\ -c \\ 0 \end{bmatrix} \\
    x, y &amp; \ge 0.
\end{align*}\]</span>
By (a variant of) Farkas’ lemma, the following dual system must have a solution.
<span class="math display">\[\begin{align*}
  \begin{bmatrix} z^T &amp; w^T &amp; t \end{bmatrix}
  \begin{bmatrix} b \\ -c \\ 0 \end{bmatrix} &amp; &lt; 0 \\
  \begin{bmatrix} z^T &amp; w^T &amp; t \end{bmatrix}
    \begin{bmatrix} A &amp; 0 \\ 0 &amp; -A^T \\ -c^T &amp; b^T \end{bmatrix}
    &amp; \ge 0\\
  z, w, t &amp; \ge 0.
\end{align*}\]</span>
which can be rewritten as
<span class="math display">\[\begin{align*}
    z^T b &amp; &lt; w^T c \\
    z^T A &amp; \ge t c^T \\
    t b^T &amp; \ge w^T A^T \\
    z, w, t &amp; \ge 0.
\end{align*}\]</span>
By combining the second and third equations, we get
<span class="math display">\[\begin{align*}
    t z^T b \ge z^T A w \ge t c^T w.
\end{align*}\]</span>
If <span class="math inline">\(t &gt; 0\)</span>, this contradicts the first equation and we’re done. So suppose <span class="math inline">\(t = 0\)</span>. Plugging in <span class="math inline">\(t = 0\)</span>, we get
<span class="math display">\[\begin{align*}
    z^T b &amp; &lt; w^T c \\
    z^T A &amp; \ge 0 \\
    0 &amp; \ge w^T A^T \\
    z, w &amp; \ge 0.
\end{align*}\]</span>
which can be rewritten as the matrix equation
<span class="math display">\[\begin{align*}
  \begin{bmatrix} z^T &amp; w^T \end{bmatrix}
  \begin{bmatrix} b \\ -c \end{bmatrix} &amp; &lt; 0 \\
  \begin{bmatrix} z^T &amp; w^T \end{bmatrix}
    \begin{bmatrix} A &amp; 0 \\ 0 &amp; -A^T \end{bmatrix}
    &amp; \ge 0\\
  z, w &amp; \ge 0.
\end{align*}\]</span>
Because this system has a solution, by applying (variant of) Farkas’ lemma again, the following system cannot have a solution.
<span class="math display">\[\begin{align*}
    \begin{bmatrix} A &amp; 0 \\ 0 &amp; -A^T \end{bmatrix}
    \begin{bmatrix} x \\ y  \end{bmatrix}
      &amp; \le
    \begin{bmatrix} b \\ -c \end{bmatrix} \\
    x, y &amp; \ge 0.
\end{align*}\]</span>
We had assumed that the primal is feasible. The only way the above system is infeasible is if there is no solution no the system
<span class="math display">\[\begin{align*}
  A^T y &amp;\ge c \\
  y &amp;\ge 0.
\end{align*}\]</span>
Applying (variant of) Farkas’ lemma yet again we see that the dual system
<span class="math display">\[\begin{align*}
  z^T c &amp; &lt; 0\\
  z^T A^T &amp;\ge 0 \\
  z &amp;\le 0
\end{align*}\]</span>
must have a solution.
But now, if <span class="math inline">\(x\)</span> is any primal-feasible solution then so is <span class="math inline">\(x - \alpha z\)</span> for any positive constant <span class="math inline">\(\alpha\)</span> and the objective value of the primal at <span class="math inline">\(x - \alpha z\)</span> can be made arbitrarily large by increasing <span class="math inline">\(\alpha\)</span> thereby contradicting the fact that primal has an optimal solution (and hence is bounded).</p>
</div>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="2">
<li id="fn2"><p>One can also define convex cones for infinite sets of vectors. In this case, we need to take the closure of the set of positive linear combinations.<a href="separation-theorems.html#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="convex-programming.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="interior-point-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": "github"
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Introduction to Optimization.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
